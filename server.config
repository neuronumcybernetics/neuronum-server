# ============================================================================
# Neuronum Agentic File Server CONFIGURATION
# ============================================================================
# This file contains all configuration parameters for the Neuronum
# Agentic File Server. Drop HTML templates into the templates/ folder
# and the agent auto-indexes them on startup.

# --- Cell ---
# Note: The mnemonic is automatically loaded from ~/.neuronum/.env
# Make sure you've run 'neuronum connect-cell' or 'neuronum create-cell' first


# --- File Paths ---
LOG_FILE = "server.log"
DB_PATH = "agent_memory.db"
TASKS_DIR = "./tasks"
TEMPLATES_DIR = "./templates"

# --- Model Configuration ---
# Maximum tokens to generate in responses
# Lower for file server: concise answers pointing users to the right page
MODEL_MAX_TOKENS = 256

# Temperature for sampling (0.0 = deterministic, 1.0 = creative)
# Low temperature: accurate, factual responses based on page content
MODEL_TEMPERATURE = 0.2

# Nucleus sampling parameter (top-p)
# Lower top-p: stick closely to the template content
MODEL_TOP_P = 0.8

# --- vLLM Server Configuration ---
# Model to load in vLLM server
# Examples: "Qwen/Qwen2.5-3B-Instruct", "Qwen/Qwen2.5-1.5B-Instruct", "meta-llama/Llama-3.2-3B-Instruct"
VLLM_MODEL_NAME = "Qwen/Qwen2.5-3B-Instruct"

# Server host (127.0.0.1 for local only, 0.0.0.0 to allow external connections)
VLLM_HOST = "127.0.0.1"

# Server port
VLLM_PORT = 8000

# Base URL for the vLLM API server (constructed from host and port)
VLLM_API_BASE = "http://127.0.0.1:8000/v1"

# --- Template Retrieval Configuration ---
# Number of recent conversation messages to include in context
CONVERSATION_HISTORY_LIMIT = 5

# Maximum number of templates to retrieve per query
# 1-2 is ideal: serve the best matching page
KNOWLEDGE_RETRIEVAL_LIMIT = 2

# FTS5 operator words to exclude from search queries (prevents syntax errors)
FTS5_STOPWORDS = {"or","and","not","near"}
